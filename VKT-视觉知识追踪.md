---
title: VKT 视觉知识追踪
---

## 说些废话

这个文章 是 我在看 知识追踪 的 paperwithcode 时候 偶然 发现一篇文章



## 前言

论文名：Visual Knowledge Tracing

链接：

1. 论文链接 https://arxiv.org/abs/2207.10157
2. 代码链接 https://github.com/nkondapa/visualknowledgetracing
3. 文章介绍链接：（知乎）https://paperswithcode.com/dataset/visual-knowledge-tracing
4. 数据集下载：https://data.caltech.edu/records/20234

相关知识：

1. 视觉分类
2.  人类类别表示 
3. 度量学习
4. 联合估计

## 1. 相关背景

​	包含三个数据集上视觉分类任务的图像和人类响应数据。数据集旨在作为视觉知识追踪算法的基准 。
​	随着人类的学习，他们的大脑会更新其提取和处理的视觉特征，从而最终决定最终的分类。在这项工作中，我们提出了一项新任务，跟踪人类学习者在从事具有挑战性的视觉分类任务时不断演变的分类行为。我们提出了联合提取学习者使用的视觉特征以及预测他们使用的分类功能的模型。 

### 1.1 相关工作



### 1.2 核心思想

### 1.2 贡献

（i）一个新的视觉知识跟踪模型，该模型联合估计了非平稳人类学习者使用的视觉特征和每时间步分类函数。
（ii）从参与学习具有挑战性的视觉分类任务的人那里收集的三个基准评估数据集的一组新注释。
（iii）详细比较了这些数据集上的几种视觉知识跟踪方法。 

## 2. 实证分析

## 3. 问题描述

## 4. 方法（基本为论文方法部分）

## 5. 总结

## 6. 自己的想法

