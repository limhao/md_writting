---
title: 双塔那些事儿
---

![](https://pic1.imgdb.cn/item/636e0ab316f2c2beb1d4be51.png)

推荐系统的双塔

解耦 user 和 item，部署时可分离

![](https://pic1.imgdb.cn/item/636e0ab316f2c2beb1d4be3d.png)

## 双塔训练

### 训练方式

三种训练方式

pointwise

pairwise

n对pairwise -- listwise softmaxwise

![](https://pic1.imgdb.cn/item/636e0ab316f2c2beb1d4be29.png)

### 样本选择

正： 用户点击物品

负：没有被召回

​        召回但是被排序模型淘汰的

​        曝光但未点击的

## DSSM初代双塔

softmaxwise loss 更新

首先使用的是百度广告

![](https://pic1.imgdb.cn/item/636e0ab316f2c2beb1d4be2d.png)

## YOUTUBE 双塔

in batch sampled softmax

![](https://pic1.imgdb.cn/item/636e0b1316f2c2beb1d59b94.png)

- 负采样

在模型中也并不需要 整个batch来作为负样本来计算

可以考虑1：10， 1：100

- 纠偏

sample-bias-corrected

u，v计算出一个score之后

通过剪出这个物品被采样的log（pj）得到一个新的score

pj的计算 可以使用全局被采样的概率来计算

- 重要经验

![](https://pic1.imgdb.cn/item/636e0ab316f2c2beb1d4be47.png)

重要经验：正则化和温度系数

如果不采用正则化 而直接采用点积 
$$
\overrightarrow{a}\cdot\overrightarrow{b}=|\overrightarrow{a}||\overrightarrow{b}|\cos\theta
$$
想让点积越大,角度越小。是我们预想的训练方向。

但是 在模型中可能会增加item向量的模 导致模型训练坍塌。

所以要使用正则化

正则化之后 数据难收敛 [-1,1]

举个例子：

模型完美的预测成功了正样本 且负采样10个 也同样完美的预测出来

但 使用正则化预测出的分数为0.42 就很拉

添加了温度系数 预测分数达到了0.999 就很强

所以需要添加 温度系数

## 负样本构造总结 -- 召回阶段很重要

![](https://pic1.imgdb.cn/item/636e0b1316f2c2beb1d59b9c.png)

## 召回元素怎么找

- 一个用户 和所有物品算相似度

效果一定好 但是时间慢了

- annoy - 只支持CPU 用的多

将物品的向量空间 通过树的形式 分割出来，确保每个树 有定量的样本

- Faiss - 啥都支持 但是 用的少

## 复现踩坑 

![](https://pic1.imgdb.cn/item/636e0b1316f2c2beb1d59bc6.png)

## 未来发展

![](https://pic1.imgdb.cn/item/636e0b1316f2c2beb1d59bd0.png)

