---
title: 图推荐系统综述
---

## 说些废话

图推荐是目前的项目需要

最近一个小伙给我又发了一篇新的 文章

需要好好读一下

2022/8/1 因为下午不能游泳 我心情很不开心 

## 前言

论文名：Graph Neural Networks for Recommender Systems: Challenges, Methods, and Directions

链接：

1. 论文链接 https://arxiv.org/abs/2109.12843
2. 代码链接 https://github.com/tsinghua-fib-lab/GNN-Recommender-Systems
3. 文章介绍链接：（知乎） 目前没有

相关知识：

	1. 图推荐系统
 	2. 图表示计算方法
 	3. 信息提取

## 1. 相关背景

- 现有的方法
  1. 谱模型
  2. 空间模型
- 动机 
  1. 高阶连通性
  2. 数据结构特征
  3. 增强的监督信号
- 挑战（）
  1. 图构造（ 适当地构造成图，节点表示元素，边表示关系 ）
  2. 嵌入传播/聚合
  3. 模型优化（ 包括优化目标、损失函数、数据采样等 ）
  4. 计算效率及有效部署（ 由于GNN的嵌入传播操作引入了大量计算，图神经网络在推荐系统中的有效部署是另一个关键挑战 ）

## 2. 标准系统及我为什么需要图数据

图！

### 2.1 结构数据

数据形式

从在线平台收集的数据有多种形式，包括用户项目交互（评级、点击、购买等）、用户档案（性别、年龄、收入等）、项目属性（品牌、类别、价格等）等 

传统的推荐系统无法利用这些多形式的数据，通常只关注一个或几个特定的数据源，由于忽略了许多信息，这导致了次优性能。通过将所有数据表示为图上的节点和边，GNN提供了一种利用可用数据的统一方法。同时，GNN在学习表示方面表现出强大的能力，因此可以获得对用户、项目和其他特征的高质量嵌入，这对推荐性能至关重要 

### 2.2 高阶连通性

在传统方法中，由于训练数据主要是仅包含直接连接项的交互记录，因此只能隐式捕获协同过滤效果。换句话说，只考虑一阶连通性。缺少高阶连通性可能会在很大程度上损害推荐性能。相反，基于GNN的模型可以有效地捕捉高阶连通性。 

### 2.3 监控信号（解决数据的稀疏问题）

监督信号在收集的数据中通常是稀疏的，而基于GNN的模型可以在表示学习过程中利用半监督信号来缓解这一问题。以电子商务平台为例；与其他行为相比，目标行为purchase相当稀少。因此，仅使用目标行为的推荐系统可能会获得较差的性能。通过在图上编码半监督信号，基于GNN的模型可以有效地结合多种非目标行为，例如搜索和添加到购物车，这可以显著提高推荐性能 

## 3. 挑战

### 3.1 图构建

数据输入为观察到的用户项交互数据，输出为缺失用户项交互的预测。因此，可以构造一个以用户/项目为节点、交互为边的二部图。此外，CF任务转向图上的用户项链接预测。 

#### 节点

 图神经网络学习的主要目标之一是为节点分配表示。这导致节点的定义在很大程度上决定了GNN模型的规模，其中大多数参数由 layer-0嵌入占据。注意，边缘嵌入通常不考虑或基于节点嵌入计算。另一方面，确定是否区分不同类型的节点也是一个具有挑战性的问题。例如，在协同过滤任务中，可以对用户节点和项目节点进行不同的建模，也可以将其视为同一类节点。另一个挑战点是处理具体的输入，例如一些数字特征，如项目价格，这些特征总是连续的数字。为了在图中表示这些特征，一种可能的解决方案是将其离散化为分类特征，然后可以将其表示为节点 

#### 边

边的定义在进一步传播和聚合以及模型优化中高度影响图的质量。在一些琐碎的任务中，推荐系统的数据输入可以被视为一种关系数据，例如用户-项目交互或用户-用户-社会关系。在一些复杂任务中，其他关系也可以表示为边。例如，在bundle推荐中，bundle由几个项组成。连接束和项目的边缘可以反映隶属关系。好的边设计在构造图时应该充分考虑图的密度。过于密集的图意味着存在度数极高的节点。这将使嵌入传播由大量邻居进行。这将进一步使传播的嵌入不可区分和无用。为了处理过于密集的边，对图进行采样、过滤或剪枝是很有希望的解决方案。当然，过于稀疏的图也会导致嵌入传播的效用较差，因为传播将仅在一小部分节点上进行。 

### 3.2 网络设计（传播和聚合的设计）

使GNN不同于传统的图学习方法的是传播层。对于传播，如何选择路径是建立推荐系统高阶相似性模型的关键。此外，传播也可以是参数化的，为不同的节点分配不同的权重。 

**在传播中，也有各种聚合函数的选择，包括均值池、LSTM、max、min等**。由于在所有推荐任务或不同数据集中没有一个选项可以表现最好，因此设计一个特定且适当的选项至关重要。此外，传播/聚集的不同选择严重影响计算效率。例如，均值池在基于GNN的推荐模型中被广泛使用，因为它可以高效地计算，**特别是对于包含高度节点的图**，例如非常流行的项目（可以连接大量用户）。此外，可以堆叠传播/聚合层，以帮助节点访问更高跳数的邻居。太浅的层使高阶图结构无法很好地建模，太深的层使节点嵌入过度平滑。这两种情况中的任何一种都会导致推荐性能较差。 

总结一下 

1. 网路设计分为 传播和聚合

2. 可以堆叠传播/聚合层 来帮助节点访问更高的邻居层

   
### 3.3 模型优化

为了优化基于图神经网络的推荐模型，推荐系统中的传统损失函数总是转向图学习损失。例如，优化中的对数损耗可以视为逐点链路预测损耗。类似地，BPR损耗[126]通常用于图上的链路预测任务。另一个方面是数据采样。在基于GNN的推荐中，要对正项目或负项目进行采样，采样方式在很大程度上取决于图结构。例如，在社交推荐中，在图上执行随机游走可以生成弱正项目（例如朋友互动的项目）。此外，有时，基于GNN的推荐可能涉及多个任务，例如不同类型边缘上的链路预测任务。那么在这种情况下，如何平衡每项任务并使它们相互促进是一个挑战。

### 3.4 计算效率

为了保证基于GNN的推荐模型的应用价值，应认真考虑其计算效率。与传统的非GNN推荐方法（如NCF或FM）相比，GNN模型的计算成本要高得多。特别是对于谱GNN模型，如GCN，每个GCN层都涉及复杂的矩阵运算。随着GCN层的多层堆叠，计算成本进一步增加。因此，PinSage等空间GNN模型更容易在大规模工业应用中实现。通过在邻域之间采样或剪枝图结构，只要我们能够承受推荐性能的下降，就可以始终保持效率。

## 4. 论文总结

### 分阶段的顶会

| 阶段       | 模型名   | 论文名                                                       | 年   | 会议 |
| ---------- | -------- | ------------------------------------------------------------ | ---- | ---- |
| Matching   | GCMC     | Graph convolutional matrix completion                        | 18   |      |
| Matching   | PinSage  | Graph convolutional neural networks for web-scale recommender systems | 18   |      |
| Matching   | NGCF     | Neural graph collaborative filtering                         | 19   |      |
| Matching   | LightGCN | Lightgcn: Simplifying and powering graph convolution network for recommendation | 20   |      |
| Ranking    | Fi-GNN   | Fi-gnn: Modeling feature interactions via graph neural networks for ctr prediction. | 19   |      |
| Ranking    | PUP      | Incorporating Price into Recommendation with Graph Convolutional Networks | 20   |      |
| Ranking    | L0-SIGN  | Detecting Beneficial Feature Interactions for Recommender Systems | 21   |      |
| Ranking    | DG-ENN   | Beyond clicks: Modeling multi-relational item graph for session-based target behavior prediction | 21   |      |
| Re-ranking | IRGPR    | Personalized Re-ranking with Item Relationships for E-commerce | 20   |      |



## 5. 总结

## 6. 自己的想法

