---
title: wandb ä½¿ç”¨æ•™ç¨‹ï¼ˆçœŸçš„å¥½ç”¨ï¼‰
---

## 0 å‰è¨€

ç›¸æ¯”TensorBoardï¼Œwandbå…·æœ‰å¦‚ä¸‹ä¸»è¦ä¼˜åŠ¿ï¼š

- æ—¥å¿—ä¸Šä¼ äº‘ç«¯æ°¸ä¹…å­˜å‚¨ï¼Œä¾¿äºåˆ†äº«ä¸æ€•ä¸¢å¤±
- å¯ä»¥å­˜ç®¡ä»£ç æ•°æ®é›†å’Œæ¨¡å‹çš„ç‰ˆæœ¬ï¼Œéšæ—¶å¤ç°ã€‚(wandb.Artifact)
- å¯ä»¥ä½¿ç”¨äº¤äº’å¼è¡¨æ ¼è¿›è¡Œcaseåˆ†æ(wandb.Table)
- å¯ä»¥è‡ªåŠ¨åŒ–æ¨¡å‹è°ƒå‚ã€‚(wandb.sweep)



wandb çš„å¹³å° èƒ½å¹²å•¥ï¼Ÿ

![](https://pic.imgdb.cn/item/64187035a682492fcc9f2327.png)

![](https://pic.imgdb.cn/item/64187034a682492fcc9f2150.png)

æ ¸å¿ƒåŠŸèƒ½æœ‰4ä¸ª

- å®éªŒè·Ÿè¸ª:experiment tracking (wandb.log)

- ç‰ˆæœ¬ç®¡ç†:version management (wandb.log_artifact, wandb.save) 

- caseåˆ†æ:case visualization (wandb.Table, wandb.Image)

- è¶…å‚è°ƒä¼˜:model optimization (wandb.sweep)

## å®éªŒè·Ÿè¸ªï¼ˆexperiment trackingï¼‰

å…ˆæ€»ç»“ä¸‹ æ¬¸ è‡ªå·±çš„æƒ³æ³•

```python
é’ˆå¯¹äº è¿™ä¸ªæ¨¡å—çš„ä½¿ç”¨
å…¶å®å°±ä¸‰æ­¥èµ°
1. wandb.init åˆå§‹åŒ–wandb
2. wandb.log æ¬¸ è®©wandb çŸ¥é“ä½ è¦è®°å•¥
3. wandb.finish å®Œäº‹äº† ä½ èµ°å§

```

![](https://pic.imgdb.cn/item/64187035a682492fcc9f2364.png)

```python
import os,PIL 
import numpy as np
from torch.utils.data import DataLoader, Dataset
import torch 
from torch import nn 
import torchvision 
from torchvision import transforms
import datetime
import wandb 
from argparse import Namespace

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# argprase è®¾ç½®è¶…å‚æ•° å¯¹äºæ¨¡å‹å¯è¯»æ€§ä¼šæ¯”è¾ƒå¥½
# å¯ä»¥é€šè¿‡config.lr æ¥è¯»å–å‚æ•°å¯è¯»æ€§ä¼šå¾ˆå¥½
config = Namespace(
    project_name = 'wandb_demo',
    
    batch_size = 512,
    
    hidden_layer_width = 64,
    dropout_p = 0.1,
    
    lr = 1e-4,
    optim_type = 'Adam',
    
    epochs = 15,
    ckpt_path = 'checkpoint.pt'
)
# åˆ›å»ºæ•°æ®é›†ä»£ç 

def create_dataloaders(config):
    transform = transforms.Compose([transforms.ToTensor()])
    ds_train = torchvision.datasets.MNIST(root="./mnist/",train=True,download=True,transform=transform)
    ds_val = torchvision.datasets.MNIST(root="./mnist/",train=False,download=True,transform=transform)

    ds_train_sub = torch.utils.data.Subset(ds_train, indices=range(0, len(ds_train), 5))
    dl_train =  torch.utils.data.DataLoader(ds_train_sub, batch_size=config.batch_size, shuffle=True,
                                            num_workers=2,drop_last=True)
    dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=config.batch_size, shuffle=False, 
                                          num_workers=2,drop_last=True)
    return dl_train,dl_val
# åœ¨è¿™é‡Œ å°±ä¼šå¼€å§‹ä½¿ç”¨ä¸€äº› configé‡Œé¢çš„è¶…å‚æ•°
def create_net(config):
    net = nn.Sequential()
    net.add_module("conv1",nn.Conv2d(in_channels=1,out_channels=config.hidden_layer_width,kernel_size = 3))
    net.add_module("pool1",nn.MaxPool2d(kernel_size = 2,stride = 2)) 
    net.add_module("conv2",nn.Conv2d(in_channels=config.hidden_layer_width,
                                     out_channels=config.hidden_layer_width,kernel_size = 5))
    net.add_module("pool2",nn.MaxPool2d(kernel_size = 2,stride = 2))
    net.add_module("dropout",nn.Dropout2d(p = config.dropout_p))
    net.add_module("adaptive_pool",nn.AdaptiveMaxPool2d((1,1)))
    net.add_module("flatten",nn.Flatten())
    net.add_module("linear1",nn.Linear(config.hidden_layer_width,config.hidden_layer_width))
    net.add_module("relu",nn.ReLU())
    net.add_module("linear2",nn.Linear(config.hidden_layer_width,10))
    net.to(device)
    return net 
# è®­ç»ƒ

def train_epoch(model,dl_train,optimizer):
    model.train()
    for step, batch in enumerate(dl_train):
        features,labels = batch
        features,labels = features.to(device),labels.to(device)

        preds = model(features)
        loss = nn.CrossEntropyLoss()(preds,labels)
        loss.backward()

        optimizer.step()
        optimizer.zero_grad()
    return model
# éªŒè¯

def eval_epoch(model,dl_val):
    model.eval()
    accurate = 0
    num_elems = 0
    for batch in dl_val:
        features,labels = batch
        features,labels = features.to(device),labels.to(device)
        with torch.no_grad():
            preds = model(features)
        predictions = preds.argmax(dim=-1)
        accurate_preds =  (predictions==labels)
        num_elems += accurate_preds.shape[0]
        accurate += accurate_preds.long().sum()

    val_acc = accurate.item() / num_elems
    return val_acc

def train(config = config):
    dl_train, dl_val = create_dataloaders(config)
    model = create_net(config); 
    optimizer = torch.optim.__dict__[config.optim_type](params=model.parameters(), lr=config.lr)
    #======================================================================
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    # åˆå§‹åŒ–è®¾ç½® éœ€è¦å°†å‚æ•°configè®¾ç½®æˆå­—å…¸ init 
    # åˆšåˆšä¸€ç›´åœ¨æƒ³è¶…å‚æ•° æ˜¯æ”¾åœ¨å“ªé‡Œçš„è¯´ 
    # åŸæ¥ä¸€ç›´åœ¨è¿™é‡Œ
    wandb.init(project=config.project_name, config = config.__dict__, name = nowtime, save_code=True)
    model.run_id = wandb.run.id
    #======================================================================
    model.best_metric = -1.0
    for epoch in range(1,config.epochs+1):
        # å…ˆtrain å val
        model = train_epoch(model,dl_train,optimizer)
        val_acc = eval_epoch(model,dl_val)
        if val_acc > model.best_metric:
            model.best_metric = val_acc
            torch.save(model.state_dict(),config.ckpt_path)   
        nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"epochã€{epoch}ã€‘@{nowtime} --> val_acc= {100 * val_acc:.2f}%")
        #======================================================================
        # åœ¨è·‘å®Œæ¨¡å‹ä¹‹å ä¿å­˜ä¸‹ æ¨¡å‹çš„æœ€å¥½çš„ç»“æœ
        wandb.log({'epoch':epoch, 'val_acc': val_acc, 'best_val_acc':model.best_metric})
        #======================================================================        
    #======================================================================
    # train å®Œä¹‹å finish 
    wandb.finish()
    #======================================================================
    return model  

"""
ä¸‰æ­¥èµ°
1. wandb init è§„å®šå¥½ é¡¹ç›®åç§° è¶…å‚æ•° runçš„è¿™ä¸€ä¸‹çš„åç§° æ˜¯å¦ä¿å­˜ä»£ç 
2. wandb.log å®šä¹‰å¥½è¦è®°å½•çš„ä¸œè¥¿ æ¥ç»˜åˆ¶æŠ˜çº¿å›¾ï¼ˆä¸€èˆ¬æ¥è¯´ acc å’Œ æœ€å¥½çš„acc æ˜¯è‚¯å®šè¦è®°å½•çš„ ï¼‰
3. wandb.finish æ‰“å®Œæ”¶å·¥  

"""
# ä¸‰æ­¥èµ° çš„ä½œç”¨ 
model = train(config) ##3,2,1 ç‚¹ç«ğŸ”¥ğŸ”¥
```

![](https://pic.imgdb.cn/item/641870c2a682492fcca0795d.png)

### metricsè®°å½•

1. é’ˆå¯¹äºè·‘è¿‡çš„è®°å½•

![](https://pic.imgdb.cn/item/64194c50a682492fcc029d68.png)

2. åœ¨æ¨¡å‹ä¸­ å¯ä»¥æ·»åŠ å›¾ æ¥å±•ç°é‡è¦æ•°æ®

![](https://pic.imgdb.cn/item/64194c50a682492fcc029dc5.png)

3. åœ¨table ä¸­ é€šè¿‡pinæ•°æ® æ¥å…³æ³¨é‡è¦æ•°æ® ç„¶å åœ¨ä¹‹å‰ä¹Ÿèƒ½å±•ç°å‡ºæ¥

![](https://pic.imgdb.cn/item/64194ce6a682492fcc038cda.png)    

![](https://pic.imgdb.cn/item/64194c50a682492fcc029d68.png)

## ç‰ˆæœ¬ç®¡ç†--æœ€ç»ˆæˆæœä¿å­˜

![](https://pic.imgdb.cn/item/64187034a682492fcc9f21fa.png)

log_artifact æ¥ä¿å­˜ä»»åŠ¡å…³è”çš„é‡è¦æˆæœ

**æ³¨:artifactç¿»è¯‘ä¸º"å·¥ä»¶"ï¼Œæ˜¯æŒ‡è½¯ä»¶å¼€å‘ä¸­äº§å‡ºçš„æœ€ç»ˆæˆæœ**

ç‰ˆæœ¬ç®¡ç† å­˜åœ¨äºä¸‰ç§

1. æ•°æ®é›†
2. æ¨¡å‹æ–‡ä»¶
3. æ¨¡å‹æƒé‡

```python
import wandb 
# é€šè¿‡æŒ‡å®šæ¨¡å‹çš„run_id æ¥æ¢å¤runä»»åŠ¡ 
# idå˜› ç‹¬ä¸€æ— äºŒ
run = wandb.init(project='wandb_demo', id= model.run_id, resume='must')
# print(model.run_id)
# save dataset 
arti_dataset = wandb.Artifact('mnist', type='dataset')
arti_dataset.add_dir('mnist/')
wandb.log_artifact(arti_dataset)
# save code 

arti_code = wandb.Artifact('ipynb', type='code')
arti_code.add_file('./1122.ipynb')
wandb.log_artifact(arti_code)
# save model

arti_model = wandb.Artifact('cnn', type='model')
arti_model.add_file(config.ckpt_path)
wandb.log_artifact(arti_model)

wandb.finish() #finishæ—¶ä¼šæäº¤ä¿å­˜
```

åœ¨å¤–é¢çš„å¤§å¾ªç¯ä¸Š å¯ä»¥çœ‹åˆ°ç»å…¸çš„ initï¼Œfinishè¿™æ ·çš„æ“ä½œ

åœ¨saveé‡Œé¢

![](https://pic.imgdb.cn/item/64194c52a682492fcc02a0fd.png)



```python
1. wandb.Artifact
2. add_dir add_file æ·»åŠ çš„æ–‡ä»¶ å‰é¢æ˜¯æ–‡ä»¶å¤¹ åé¢æ˜¯æ–‡ä»¶
3. wandb.log_artifact ä¿å­˜æ–‡ä»¶
```

## caseåˆ†æ

![](https://pic.imgdb.cn/item/6419ba9aa682492fccdac702.png)

```python
import wandb 
run = wandb.init(project=config.project_name, id= model.run_id, resume='must')

mport matplotlib.pyplot as plt 

transform = transforms.Compose([transforms.ToTensor()])
ds_train = torchvision.datasets.MNIST(root="./mnist/",train=True,download=True,transform=transform)
ds_val = torchvision.datasets.MNIST(root="./mnist/",train=False,download=True,transform=transform)
# å¸¸è§„çš„matplotlib åˆ†æ
# visual the  prediction
device = None
for p in model.parameters():
    device = p.device
    break

plt.figure(figsize=(8,8)) 
for i in range(9):
    img,label = ds_val[i]
    tensor = img.to(device)
    y_pred = torch.argmax(model(tensor[None,...])) 
    img = img.permute(1,2,0)
    ax=plt.subplot(3,3,i+1)
    ax.imshow(img.numpy())
    ax.set_title("y_pred = %d"%y_pred)
    ax.set_xticks([])
    ax.set_yticks([]) 
plt.show()    
```
- å®šä¹‰è¾…åŠ©å‡½æ•° ä¸æ˜¯å¿…é¡»çš„
```python
def data2fig(data):
    # å›¾åƒè½¬æ¢æˆ matplotlib 
    import matplotlib.pyplot as plt 
    fig = plt.figure()
    ax = fig.add_subplot()
    ax.imshow(data)
    ax.set_xticks([])
    ax.set_yticks([]) 
    return fig

def fig2img(fig):
    # matè½¬æ¢æˆplo
    import io,PIL
    buf = io.BytesIO()
    fig.savefig(buf)
    buf.seek(0)
    img = PIL.Image.open(buf)
    return img
```

**å¼€å§‹é‡è¦çš„äº†**

```python
# è¿™é‡Œä½¿ç”¨äº† wandb.table å‡½æ•°
from tqdm import tqdm 
good_cases = wandb.Table(columns = ['Image','GroundTruth','Prediction'])
bad_cases = wandb.Table(columns = ['Image','GroundTruth','Prediction'])
```

- ä½œä¸ºtable æ˜¯å¯ä»¥æ·»åŠ  æ•°æ®çš„ add_data

```python
plt.close()
# æ‰¾åˆ°50ä¸ªgood cases å’Œ 50 ä¸ªbad cases

for i in tqdm(range(1000)):
    features,label = ds_val[i]
    tensor = features.to(device)
    y_pred = torch.argmax(model(tensor[None,...])) 
    
    # log badcase
    if y_pred!=label:
        if len(bad_cases.data)<50:
            data = features.permute(1,2,0).numpy()
            input_img = wandb.Image(fig2img(data2fig(data)))
            bad_cases.add_data(input_img,label,y_pred)
            
    # log goodcase
    else:
        if len(good_cases.data)<50:
            data = features.permute(1,2,0).numpy()
            input_img = wandb.Image(fig2img(data2fig(data)))
            good_cases.add_data(input_img,label,y_pred)
```

- æœ€åä¸¤æ­¥

```python
wandb.log({'good_cases':good_cases,'bad_cases':bad_cases})
wandb.finish()
```

![](https://pic.imgdb.cn/item/6419ba9aa682492fccdac6aa.png)